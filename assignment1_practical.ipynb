{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1lAy_YT2kZxUVJvk7umNcXW3_Ded87R2i",
      "authorship_tag": "ABX9TyPWNVTuWP6v7C8hjv3nLaTD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mitkrieg/dl-assignment-1/blob/main/assignment1_practical.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7roLS_owoJPv",
        "outputId": "87e025cd-034a-42ab-c84d-dd331f12526e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.transforms import ToTensor\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "import gzip\n",
        "import typing as T\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data using Pytorch"
      ],
      "metadata": {
        "id": "yWsWErVcSRIv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "PATH = '/content/drive/MyDrive/Fall 2024/Deep Learning/Assignment 1/data'\n",
        "\n"
      ],
      "metadata": {
        "id": "kGjJiU0lDHzb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FasionMINSTDataset(Dataset):\n",
        "  def __init__(self, path: str, kind: str, transform=None, target_transform=None) -> None:\n",
        "    self.transform = transform\n",
        "    self.target_transform = target_transform\n",
        "    self.labels, self.images = self._load_data(path, kind)\n",
        "    self.labels_map = {\n",
        "            0: \"T-Shirt\",\n",
        "            1: \"Trouser\",\n",
        "            2: \"Pullover\",\n",
        "            3: \"Dress\",\n",
        "            4: \"Coat\",\n",
        "            5: \"Sandal\",\n",
        "            6: \"Shirt\",\n",
        "            7: \"Sneaker\",\n",
        "            8: \"Bag\",\n",
        "            9: \"Ankle Boot\",\n",
        "        }\n",
        "\n",
        "  def _load_data(self, path: str, kind: str) -> T.Tuple[np.ndarray, np.ndarray]:\n",
        "    with gzip.open(path + f'/{kind}-labels-idx1-ubyte.gz', 'rb') as lable_file:\n",
        "      lbls = np.frombuffer(lable_file.read(), dtype=np.int8, offset=8)\n",
        "      lbls = np.copy(lbls)\n",
        "    with gzip.open(path + f'/{kind}-images-idx3-ubyte.gz', 'rb') as lable_file:\n",
        "      imgs = np.frombuffer(lable_file.read(), dtype=np.uint8, offset=16).reshape(len(lbls), 1, 28, 28)\n",
        "      imgs = (np.copy(imgs) / 255).astype(np.float32)\n",
        "    return lbls, imgs\n",
        "\n",
        "  def __len__(self) -> int:\n",
        "    return self.labels.size\n",
        "\n",
        "  def __getitem__(self, index) -> T.Union[T.Dict[str, T.Any],T.List[T.Dict[str, T.Any]]]:\n",
        "    label = torch.tensor(self.labels[index], dtype=torch.long)\n",
        "    img = torch.tensor(self.images[index])\n",
        "\n",
        "    if self.target_transform:\n",
        "      label = self.target_transform(label)\n",
        "    if self.transform:\n",
        "      img = self.transform(img)\n",
        "\n",
        "\n",
        "    return img, label\n",
        "\n",
        "  def show_img(self, index):\n",
        "    label = self.labels[index]\n",
        "    img = self.images[index]\n",
        "    plt.imshow(img.reshape(28,28), cmap='gray')\n",
        "    plt.title(self.labels_map[label])\n",
        "\n",
        "\n",
        "train = FasionMINSTDataset(PATH, 'train')\n",
        "test = FasionMINSTDataset(PATH, 'test')"
      ],
      "metadata": {
        "id": "1gxeQbXyRrqN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch = 32\n",
        "trainloader = DataLoader(train, batch, shuffle=True, num_workers=2)\n",
        "testloader = DataLoader(test, batch, shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "id": "JXMp90QEcxwP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Lenet5(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 6, kernel_size=5, stride=1)\n",
        "    self.avg_pool1 = nn.AvgPool2d(2, 2)\n",
        "    self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=1)\n",
        "    self.avg_pool2 = nn.AvgPool2d(2, 2)\n",
        "    self.fc1 = nn.Linear(16*4*4, 120)\n",
        "    self.fc2 = nn.Linear(120, 84)\n",
        "    self.fc3 = nn.Linear(84,10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.tanh(self.conv1(x))\n",
        "    x = self.avg_pool1(x)\n",
        "    x = F.tanh(self.conv2(x))\n",
        "    x = self.avg_pool2(x)\n",
        "    x = torch.flatten(x, 1)\n",
        "    x = F.tanh(self.fc1(x))\n",
        "    x = F.tanh(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x\n",
        "\n",
        "net = Lenet5(batch)\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=1e-3, momentum=0.9)"
      ],
      "metadata": {
        "id": "p0PflE0mV3Q7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(5):\n",
        "  total_loss = 0\n",
        "  for i, data in enumerate(trainloader):\n",
        "    inputs, labels = data\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    outputs = net(inputs)\n",
        "    loss = loss_function(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss += loss.item()\n",
        "    if i % 64 == 63:\n",
        "      print(f'Epoch #{epoch + 1}, Batch #{i + 1}: {total_loss / 64}')\n",
        "      total_loss = 0\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hp6BRgVybpiY",
        "outputId": "a24e861a-5756-45e1-fe67-bfbf137fcb13"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #1, Batch #64: 2.3044502213597298\n",
            "Epoch #1, Batch #128: 2.2952739894390106\n",
            "Epoch #1, Batch #192: 2.282403290271759\n",
            "Epoch #1, Batch #256: 2.2680815905332565\n",
            "Epoch #1, Batch #320: 2.244790866971016\n",
            "Epoch #1, Batch #384: 2.2054286375641823\n",
            "Epoch #1, Batch #448: 2.128204472362995\n",
            "Epoch #1, Batch #512: 1.9951631464064121\n",
            "Epoch #1, Batch #576: 1.7966137751936913\n",
            "Epoch #1, Batch #640: 1.6062350161373615\n",
            "Epoch #1, Batch #704: 1.4634484015405178\n",
            "Epoch #1, Batch #768: 1.3225453738123178\n",
            "Epoch #1, Batch #832: 1.2668433412909508\n",
            "Epoch #1, Batch #896: 1.1951732262969017\n",
            "Epoch #1, Batch #960: 1.1503965305164456\n",
            "Epoch #1, Batch #1024: 1.1562119079753757\n",
            "Epoch #1, Batch #1088: 1.0958245769143105\n",
            "Epoch #1, Batch #1152: 1.0464043989777565\n",
            "Epoch #1, Batch #1216: 1.0475705387070775\n",
            "Epoch #1, Batch #1280: 1.0401470763608813\n",
            "Epoch #1, Batch #1344: 1.0069887405261397\n",
            "Epoch #1, Batch #1408: 0.9924458032473922\n",
            "Epoch #1, Batch #1472: 0.9966997699812055\n",
            "Epoch #1, Batch #1536: 0.92018848285079\n",
            "Epoch #1, Batch #1600: 0.9424315122887492\n",
            "Epoch #1, Batch #1664: 0.8906210269778967\n",
            "Epoch #1, Batch #1728: 0.8898487342521548\n",
            "Epoch #1, Batch #1792: 0.8737050918862224\n",
            "Epoch #1, Batch #1856: 0.8621350391767919\n",
            "Epoch #2, Batch #64: 0.8361746352165937\n",
            "Epoch #2, Batch #128: 0.8351619159802794\n",
            "Epoch #2, Batch #192: 0.8580762287601829\n",
            "Epoch #2, Batch #256: 0.8034327165223658\n",
            "Epoch #2, Batch #320: 0.7910579806193709\n",
            "Epoch #2, Batch #384: 0.7654661992564797\n",
            "Epoch #2, Batch #448: 0.799673842266202\n",
            "Epoch #2, Batch #512: 0.7533421693369746\n",
            "Epoch #2, Batch #576: 0.7531617423519492\n",
            "Epoch #2, Batch #640: 0.7585174152627587\n",
            "Epoch #2, Batch #704: 0.7619519792497158\n",
            "Epoch #2, Batch #768: 0.7315583103336394\n",
            "Epoch #2, Batch #832: 0.7670418862253428\n",
            "Epoch #2, Batch #896: 0.7185678402893245\n",
            "Epoch #2, Batch #960: 0.7311983606778085\n",
            "Epoch #2, Batch #1024: 0.7211161367595196\n",
            "Epoch #2, Batch #1088: 0.7146683391183615\n",
            "Epoch #2, Batch #1152: 0.7205463382415473\n",
            "Epoch #2, Batch #1216: 0.7246018750593066\n",
            "Epoch #2, Batch #1280: 0.6974752880632877\n",
            "Epoch #2, Batch #1344: 0.69221869437024\n",
            "Epoch #2, Batch #1408: 0.706471866928041\n",
            "Epoch #2, Batch #1472: 0.7053164709359407\n",
            "Epoch #2, Batch #1536: 0.7222762573510408\n",
            "Epoch #2, Batch #1600: 0.6613203482702374\n",
            "Epoch #2, Batch #1664: 0.6492846822366118\n",
            "Epoch #2, Batch #1728: 0.68040502211079\n",
            "Epoch #2, Batch #1792: 0.6853592321276665\n",
            "Epoch #2, Batch #1856: 0.6885090786963701\n",
            "Epoch #3, Batch #64: 0.6520846919156611\n",
            "Epoch #3, Batch #128: 0.6757431346923113\n",
            "Epoch #3, Batch #192: 0.6480734604410827\n",
            "Epoch #3, Batch #256: 0.6702865287661552\n",
            "Epoch #3, Batch #320: 0.6654426050372422\n",
            "Epoch #3, Batch #384: 0.6706328089348972\n",
            "Epoch #3, Batch #448: 0.6558191077783704\n",
            "Epoch #3, Batch #512: 0.6407136814668775\n",
            "Epoch #3, Batch #576: 0.6815220499411225\n",
            "Epoch #3, Batch #640: 0.6420672074891627\n",
            "Epoch #3, Batch #704: 0.6178978569805622\n",
            "Epoch #3, Batch #768: 0.6326798438094556\n",
            "Epoch #3, Batch #832: 0.6477417480200529\n",
            "Epoch #3, Batch #896: 0.6147146304138005\n",
            "Epoch #3, Batch #960: 0.6237303549423814\n",
            "Epoch #3, Batch #1024: 0.6310293283313513\n",
            "Epoch #3, Batch #1088: 0.6138109331950545\n",
            "Epoch #3, Batch #1152: 0.6052697976119816\n",
            "Epoch #3, Batch #1216: 0.6646561026573181\n",
            "Epoch #3, Batch #1280: 0.6477359416894615\n",
            "Epoch #3, Batch #1344: 0.6399208018556237\n",
            "Epoch #3, Batch #1408: 0.6040110723115504\n",
            "Epoch #3, Batch #1472: 0.6238539316691458\n",
            "Epoch #3, Batch #1536: 0.616848524659872\n",
            "Epoch #3, Batch #1600: 0.6022933409549296\n",
            "Epoch #3, Batch #1664: 0.5948732891120017\n",
            "Epoch #3, Batch #1728: 0.6095396061427891\n",
            "Epoch #3, Batch #1792: 0.6006788844242692\n",
            "Epoch #3, Batch #1856: 0.592063111718744\n",
            "Epoch #4, Batch #64: 0.5663377000018954\n",
            "Epoch #4, Batch #128: 0.6067755199037492\n",
            "Epoch #4, Batch #192: 0.5875591880176216\n",
            "Epoch #4, Batch #256: 0.5879280637018383\n",
            "Epoch #4, Batch #320: 0.582329751458019\n",
            "Epoch #4, Batch #384: 0.5869982070289552\n",
            "Epoch #4, Batch #448: 0.589618154335767\n",
            "Epoch #4, Batch #512: 0.5976741281338036\n",
            "Epoch #4, Batch #576: 0.5707925425376743\n",
            "Epoch #4, Batch #640: 0.6116495996247977\n",
            "Epoch #4, Batch #704: 0.5617552879266441\n",
            "Epoch #4, Batch #768: 0.5754628204740584\n",
            "Epoch #4, Batch #832: 0.5570967267267406\n",
            "Epoch #4, Batch #896: 0.5801101825200021\n",
            "Epoch #4, Batch #960: 0.6067997813224792\n",
            "Epoch #4, Batch #1024: 0.5657436035107821\n",
            "Epoch #4, Batch #1088: 0.5690213898196816\n",
            "Epoch #4, Batch #1152: 0.5835691848769784\n",
            "Epoch #4, Batch #1216: 0.572462294716388\n",
            "Epoch #4, Batch #1280: 0.5415618654806167\n",
            "Epoch #4, Batch #1344: 0.5329631404019892\n",
            "Epoch #4, Batch #1408: 0.5455322810448706\n",
            "Epoch #4, Batch #1472: 0.5803294531069696\n",
            "Epoch #4, Batch #1536: 0.5525738974101841\n",
            "Epoch #4, Batch #1600: 0.5426881331950426\n",
            "Epoch #4, Batch #1664: 0.5566628756932914\n",
            "Epoch #4, Batch #1728: 0.562477913685143\n",
            "Epoch #4, Batch #1792: 0.5653158100321889\n",
            "Epoch #4, Batch #1856: 0.5173669927753508\n",
            "Epoch #5, Batch #64: 0.5683165290392935\n",
            "Epoch #5, Batch #128: 0.5578597080893815\n",
            "Epoch #5, Batch #192: 0.5487772673368454\n",
            "Epoch #5, Batch #256: 0.5313701429404318\n",
            "Epoch #5, Batch #320: 0.5250013240147382\n",
            "Epoch #5, Batch #384: 0.5396882651839405\n",
            "Epoch #5, Batch #448: 0.5204514428041875\n",
            "Epoch #5, Batch #512: 0.5193113372661173\n",
            "Epoch #5, Batch #576: 0.5067394566722214\n",
            "Epoch #5, Batch #640: 0.5301336979027838\n",
            "Epoch #5, Batch #704: 0.5331797602120787\n",
            "Epoch #5, Batch #768: 0.5542990907561034\n",
            "Epoch #5, Batch #832: 0.5309570792596787\n",
            "Epoch #5, Batch #896: 0.5134316547773778\n",
            "Epoch #5, Batch #960: 0.5353294059168547\n",
            "Epoch #5, Batch #1024: 0.5370922004804015\n",
            "Epoch #5, Batch #1088: 0.5125754177570343\n",
            "Epoch #5, Batch #1152: 0.49999139178544283\n",
            "Epoch #5, Batch #1216: 0.5346493315882981\n",
            "Epoch #5, Batch #1280: 0.5072393438313156\n",
            "Epoch #5, Batch #1344: 0.5255440000910312\n",
            "Epoch #5, Batch #1408: 0.5213659245055169\n",
            "Epoch #5, Batch #1472: 0.5205004308372736\n",
            "Epoch #5, Batch #1536: 0.5106775937601924\n",
            "Epoch #5, Batch #1600: 0.5697890380397439\n",
            "Epoch #5, Batch #1664: 0.5330211874097586\n",
            "Epoch #5, Batch #1728: 0.4918585035484284\n",
            "Epoch #5, Batch #1792: 0.4878499007318169\n",
            "Epoch #5, Batch #1856: 0.48172202054411173\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the {len(test)} test images: {100 * correct // total} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgIsied7fW0a",
        "outputId": "64139310-fba7-4289-da74-7bfba9b39f10"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 79 %\n"
          ]
        }
      ]
    }
  ]
}